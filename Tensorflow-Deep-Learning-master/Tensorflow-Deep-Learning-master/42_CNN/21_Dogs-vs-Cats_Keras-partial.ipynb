{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats\n",
    "## Kaggle Dataset의 일부를 이용한 개, 고양이 구분\n",
    "### Dog Image: 1,111개, Cat Image: 1,111개, 총 2,222개\n",
    "### 출처: [pontoregende GitHub](https://github.com/pontorezende/Dogs-vs-Cats-Redux-with-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2, os, random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='dogs-vs-cats/train/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## used for resize and in our model\n",
    "ROW, COL = 96, 96\n",
    "\n",
    "dogs, cats = [], []\n",
    "y_dogs, y_cats = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_path = os.path.join (path, 'dog.5*')\n",
    "len(glob(dog_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load some our dog images (1,111 개 이미지)\n",
    "dog_path = os.path.join(path, 'dog.5*')\n",
    "for dog_img in glob(dog_path):\n",
    "    dog = cv2.imread(dog_img)\n",
    "    dog = cv2.cvtColor(dog, cv2.COLOR_BGR2GRAY)\n",
    "    dog = cv2.resize(dog, (ROW, COL))\n",
    "    dog = image.img_to_array(dog)\n",
    "    dogs.append(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load some our cat images (1,111 개 이미지)\n",
    "cat_path = os.path.join(path, 'cat.5*')\n",
    "for cat_img in glob(cat_path):\n",
    "    cat = cv2.imread(cat_img)\n",
    "    cat = cv2.cvtColor(cat, cv2.COLOR_BGR2GRAY)\n",
    "    cat = cv2.resize(cat, (ROW, COL))\n",
    "    cat = image.img_to_array(cat)\n",
    "    cats.append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['dog', 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-20b2b726849d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\random.py\u001b[0m in \u001b[0;36mchoice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAAHWCAYAAADww4JFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMpklEQVR4nO3aX4il913H8ffH3Qa0/qmYVetuViKsjSu00o6xgn8iRd3kZin0IqlYDMISacTL5qq96JUXgpSmXZYSSm+aG0tdy7a5017USCbSptmWlDHFZtxCklYqtWLY9uvFjDJOZzNnN2f2k5x5v2Bgnuf5nXO+T86b58zZJ5kZpJYfaQ+gw80AVWWAqjJAVRmgqgxQVfsGmOSRJM8nefoax5PkQ0k2kjyV5K3LH1OrapEr4MeBMy9z/G7g1PbPOeCjr3wsHRb7Bjgznwe+/TJLzgKfmC2PA29I8sZlDajVtoy/AY8Dz+3Y3tzeJ+3r6BKeI3vs2/P+XpJzbH1M8/rXv/5td9xxxxJeXq8GTz755Iszc+x6H7eMADeB23ZsnwCu7LVwZi4AFwDW1tZmfX19CS+vV4Mk/3ojj1vGR/BF4D3b34bfDnxnZr65hOfVIbDvFTDJJ4G7gFuTbAIfAF4HMDPngUvAPcAG8D3g/oMaVqtn3wBn5r59jg/w3qVNpEPFOyGqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1TVQgEmOZPkmSQbSR7a4/hPJfm7JF9KcjnJ/csfVato3wCTHAEeBu4GTgP3JTm9a9l7ga/MzFuAu4C/SnLLkmfVClrkCngnsDEzz87MS8CjwNldawb4iSQBfhz4NnB1qZNqJS0S4HHguR3bm9v7dvow8CvAFeDLwF/MzA+WMqFW2iIBZo99s2v7D4EvAr8A/Brw4SQ/+UNPlJxLsp5k/YUXXrjuYbV6FglwE7htx/YJtq50O90PfGq2bABfB+7Y/UQzc2Fm1mZm7dixYzc6s1bIIgE+AZxKcvv2F4t7gYu71nwDeAdAkp8D3gQ8u8xBtZqO7rdgZq4meRB4DDgCPDIzl5M8sH38PPBB4ONJvszWR/b7ZubFA5xbK2LfAAFm5hJwade+8zt+vwL8wXJH02HgnRBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAapqoQCTnEnyTJKNJA9dY81dSb6Y5HKSf1jumFpVR/dbkOQI8DDw+8Am8ESSizPzlR1r3gB8BDgzM99I8rMHNbBWyyJXwDuBjZl5dmZeAh4Fzu5a827gUzPzDYCZeX65Y2pVLRLgceC5Hdub2/t2+mXgp5P8fZInk7xnWQNqte37EQxkj32zx/O8DXgH8KPAPyZ5fGa+9v+eKDkHnAM4efLk9U+rlbPIFXATuG3H9gngyh5rPjcz/zkzLwKfB96y+4lm5sLMrM3M2rFjx250Zq2QRQJ8AjiV5PYktwD3Ahd3rflb4LeTHE3yY8BvAF9d7qhaRft+BM/M1SQPAo8BR4BHZuZykge2j5+fma8m+RzwFPAD4GMz8/RBDq7VkJndf87dHGtra7O+vl55bS1fkidnZu16H+edEFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqmqhAJOcSfJMko0kD73Mul9P8v0k71reiFpl+waY5AjwMHA3cBq4L8npa6z7S+CxZQ+p1bXIFfBOYGNmnp2Zl4BHgbN7rPtz4G+A55c4n1bcIgEeB57bsb25ve//JDkOvBM4v7zRdBgsEmD22De7tv8aeN/MfP9lnyg5l2Q9yfoLL7yw6IxaYUcXWLMJ3LZj+wRwZdeaNeDRJAC3AvckuTozn965aGYuABcA1tbWdkesQ2iRAJ8ATiW5Hfg34F7g3TsXzMzt//t7ko8Dn9kdn7SXfQOcmatJHmTr2+0R4JGZuZzkge3j/t2nG7bIFZCZuQRc2rVvz/Bm5k9e+Vg6LLwToioDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVS0UYJIzSZ5JspHkoT2O/1GSp7Z/vpDkLcsfVato3wCTHAEeBu4GTgP3JTm9a9nXgd+dmTcDHwQuLHtQraZFroB3Ahsz8+zMvAQ8CpzduWBmvjAz/769+ThwYrljalUtEuBx4Lkd25vb+67lT4HPvpKhdHgcXWBN9tg3ey5Mfo+tAH/rGsfPAecATp48ueCIWmWLXAE3gdt2bJ8AruxelOTNwMeAszPzrb2eaGYuzMzazKwdO3bsRubVilkkwCeAU0luT3ILcC9wceeCJCeBTwF/PDNfW/6YWlX7fgTPzNUkDwKPAUeAR2bmcpIHto+fB94P/AzwkSQAV2dm7eDG1qrIzJ5/zh24tbW1WV9fr7y2li/Jkzdy0fFOiKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVWWAqjJAVRmgqgxQVQaoKgNUlQGqygBVZYCqMkBVGaCqDFBVBqgqA1SVAarKAFVlgKoyQFUZoKoMUFUGqCoDVJUBqsoAVbVQgEnOJHkmyUaSh/Y4niQf2j7+VJK3Ln9UraJ9A0xyBHgYuBs4DdyX5PSuZXcDp7Z/zgEfXfKcWlGLXAHvBDZm5tmZeQl4FDi7a81Z4BOz5XHgDUneuORZtYIWCfA48NyO7c3tfde7RvohRxdYkz32zQ2sIck5tj6iAf47ydMLvP5r3a3Ai+0hboI33ciDFglwE7htx/YJ4MoNrGFmLgAXAJKsz8zadU37GnSYzvNGHrfIR/ATwKkktye5BbgXuLhrzUXgPdvfht8OfGdmvnkjA+lw2fcKODNXkzwIPAYcAR6ZmctJHtg+fh64BNwDbADfA+4/uJG1SjLzQ3+q3ZwXTs5tfySvNM9zn8e1ApTAW3EqO/AAD8ttvAXO864k30nyxe2f9zfmfCWSPJLk+Wv989kNvZczc2A/bH1p+Rfgl4BbgC8Bp3etuQf4LFv/lvh24J8Ocqbied4FfKY96ys8z98B3go8fY3j1/1eHvQV8LDcxlvkPF/zZubzwLdfZsl1v5cHHeBhuY236Dn8ZpIvJflskl+9OaPdVNf9Xi5yJ+SVWNptvFe5Rc7hn4FfnJnvJrkH+DRb//fQKrnu9/Kgr4BLu433KrfvOczMf8zMd7d/vwS8LsmtN2/Em+K638uDDvCw3Mbb9zyT/HySbP9+J1v/7b910yc9WNf9Xh7oR/Acktt4C57nu4A/S3IV+C/g3tn+6vhakeSTbH2bvzXJJvAB4HVw4++ld0JU5Z0QVRmgqgxQVQaoKgNUlQGqygBVZYCq+h90rGaWbL1tfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))    \n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    img = image.array_to_img(random.choice(dogs))\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('It should be a {}.'.format(classes[0]))        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    img = image.array_to_img(random.choice(cats))\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.title('It should be a {}.'.format(classes[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just change the labels for 0 and  1\n",
    "y_dogs = [1 for item in enumerate(dogs)]\n",
    "y_cats = [0 for item in enumerate(cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting everything to Numpy array to fit in our model\n",
    "## them creating a X and target file like we used to see\n",
    "## in Machine and Deep Learning models\n",
    "dogs = np.asarray(dogs).astype('float32') / 255\n",
    "cats = np.asarray(cats).astype('float32') / 255\n",
    "y_dogs = np.asarray(y_dogs).astype('int32')\n",
    "y_cats = np.asarray(y_cats).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((dogs,cats), axis=0)\n",
    "y = np.concatenate((y_dogs, y_cats), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Hot Encoding\n",
    "y = tf.keras.utils.to_categorical(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here is our model as a CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', input_shape=(ROW, COL, 1), \n",
    "           activation='relu'),\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to save checkpoint to use later\n",
    "modelpath = \"model/dogs_vs_cats-cnn-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=40, validation_split=0.2,\n",
    "          callbacks=[checkpointer, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "del model\n",
    "model = load_model('model/dogs_vs_cats-cnn-07-0.6036.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X, y, verbose=2)\n",
    "print('MODEL ACCURACY: %.5f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X, y, verbose=2)\n",
    "print('MODEL ACCURACY: %.5f' % scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
